{"cells":[{"cell_type":"markdown","metadata":{"id":"Zgqyn7IOdVrR"},"source":["# ABP EVALUACI√ìN MODULO 3\n","### Flujo de Trabajo para las etapas de carga, limpieza, transformaci√≥n y estructuraci√≥n de datos."]},{"cell_type":"markdown","metadata":{"id":"uo-1fMpZcpj9"},"source":["## Objetivos del Proyecto\n","El objetivo principal del proyecto es desarrollar un proceso automatizado y\n","eficiente para la obtenci√≥n, limpieza, transformaci√≥n, an√°lisis y estructuraci√≥n\n","de datos utilizando Python y las librer√≠as NumPy y Pandas.\n","\n","\n","Este objetivo responde a la necesidad de la empresa de disponer de datos de\n","calidad para la elaboraci√≥n de reportes estrat√©gicos y la implementaci√≥n de\n","modelos de machine learning.\n","\n","### Qu√© se espera\n","Al finalizar el proyecto, se espera contar con un dataset limpio, confiable y\n","estructurado, listo para ser utilizado en procesos de an√°lisis y toma de decisiones en la organizaci√≥n."]},{"cell_type":"markdown","metadata":{"id":"htHzz_OSdpg3"},"source":["## Lecci√≥n 1 - La librer√≠a numpy\n","üéØ Objetivo: Crear un conjunto de datos ficticio utilizando NumPy,\n","aplicando operaciones b√°sicas para la preparaci√≥n inicial.\n","\n","üìç Tareas a desarrollar:\n","\n","1.   Crear un archivo .py o un Notebook .ipynb.\n","2.   Generar datos ficticios de clientes y transacciones utilizando\n","arrays de NumPy.\n","3.   Aplicar operaciones matem√°ticas b√°sicas\n"," (suma, media, conteo, etc.).\n","4. Guardar los datos generados en un archivo .npy o convertirlos\n","a listas para usarlos luego en Pandas.\n","5. Explicar en un breve documento por qu√© NumPy es eficiente\n","para el manejo de datos num√©ricos.\n","\n","‚Üí Nota: Este archivo servir√° de insumo para la siguiente lecci√≥n,\n","donde estos datos ser√°n cargados y explorados con Pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUgeEJCFfPDI"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cH2CtXUDMZbO"},"outputs":[],"source":["# 2. Generar datos ficticios de clientes y transacciones usando arrays de NumPy\n","np.random.seed(42) # Para reproducibilidad\n","\n","num_clientes = 100\n","num_transacciones = 500\n","\n","# Datos de Clientes: ID, Edad, Sexo(0/1)\n","cliente_ids = np.arange(1, num_clientes + 1)\n","edades = np.random.randint(18, 70, size=num_clientes)\n","sexo = np.random.randint(0, 2, size=num_clientes) # 0= femenino, 1=Masculino\n","\n","# Datos de Transacciones: ID Transacci√≥n, ID Cliente, Monto, Tipo Transaccion(A/B/C)\n","transaccion_ids = np.arange(1001, 1001 + num_transacciones)\n","\n","# Asigna transacciones aleatoriamente a los clientes existentes\n","cliente_ids_transaccion = np.random.choice(cliente_ids, size=num_transacciones)\n","\n","montos = np.random.rand(num_transacciones) * 1000 + 10 # Montos entre 10 y 1010\n","# 1. Generar montos normales (Rango 10 - 1010)\n","montos = np.random.rand(num_transacciones) * 1000 + 10\n","\n","# Inyectar OUTLIERS manualmente\n","# Elegimos 10 √≠ndices aleatorios para convertirlos en compras masivas\n","num_outliers = 10\n","indices_outliers = np.random.choice(range(num_transacciones), size=num_outliers, replace=False)\n","# Asignamos montos muy elevados (ej: entre 5000 y 15000)\n","montos[indices_outliers] = np.random.uniform(5000, 15000, size=num_outliers)\n","\n","# Simulaci√≥n de tipos de transacci√≥n A=0, B=1, C=2\n","tipos = np.random.randint(0, 3, size=num_transacciones)\n","\n","comuna_ids = np.random.randint(1, 347, size=num_transacciones)\n","\n","# Consolidar datos en arrays 2D para manejo m√°s f√°cil (aunque NumPy es flexible)\n","datos_clientes = np.column_stack([cliente_ids, edades, sexo])\n","datos_transacciones = np.column_stack([transaccion_ids, cliente_ids_transaccion, comuna_ids,montos, tipos])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1769883780686,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"TK-2hTqNdoMO","outputId":"7a103b18-3dc6-4a62-9505-12b119a96a38"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Operaciones B√°sicas con NumPy ---\n","N√∫mero total de transacciones: 500\n","Suma total de todos los montos: $347407.24\n","Monto promedio por transacci√≥n: $694.81\n","Monto m√°ximo de transacci√≥n: $14565.01\n","Edad promedio de clientes: 43.4 a√±os\n","\n","Datos de clientes y transacciones guardados en archivos .npy.\n"]}],"source":["\n","# 3. Aplicar operaciones matem√°ticas b√°sicas (suma, media, conteo, etc.)\n","print(\"--- Operaciones B√°sicas con NumPy ---\")\n","print(f\"N√∫mero total de transacciones: {montos.size}\")\n","print(f\"Suma total de todos los montos: ${np.sum(montos):.2f}\")\n","print(f\"Monto promedio por transacci√≥n: ${np.mean(montos):.2f}\")\n","print(f\"Monto m√°ximo de transacci√≥n: ${np.max(montos):.2f}\")\n","print(f\"Edad promedio de clientes: {np.mean(edades):.1f} a√±os\")\n","\n","# 4. Guardar los datos generados en un archivo .npy\n","np.save('clientes.npy', datos_clientes)\n","np.save('transacciones.npy', datos_transacciones)\n","print(\"\\nDatos de clientes y transacciones guardados en archivos .npy.\")\n","\n","# Preparar listas para la Lecci√≥n 2 si es necesario (alternativa a .npy)\n","# clientes_list = datos_clientes.tolist()\n","# transacciones_list = datos_transacciones.tolist()"]},{"cell_type":"markdown","metadata":{"id":"6wi1NRmygWJ7"},"source":["## 5. Explicaci√≥n de la eficiencia de NumPy\n","\n","### Documento Breve: ¬øPor qu√© NumPy es eficiente?\n","NumPy es fundamental en la computaci√≥n cient√≠fica en Python por su eficiencia superior en el manejo de datos num√©ricos comparado con las listas nativas de Python. Las razones clave son:\n","\n","**Implementaci√≥n en C:** El n√∫cleo de NumPy est√° escrito en C, lo que permite que\n","las operaciones se ejecuten mucho m√°s cerca del hardware y a velocidades nativas, evitando el overhead del int√©rprete de Python.\n","\n","**Vectorizaci√≥n de Operaciones:** NumPy permite realizar operaciones matem√°ticas sobre arrays enteros a la vez (ej. np.sum(montos)), en lugar de iterar elemento por elemento con bucles expl√≠citos de Python. Esto se conoce como operaciones vectorizadas y es mucho m√°s r√°pido.\n","\n","**Almacenamiento Eficiente de Memoria:** Los arrays de NumPy almacenan elementos del mismo tipo de datos de manera contigua en memoria. Esto mejora la localidad de referencia del cach√© de la CPU, optimizando el acceso y la manipulaci√≥n de datos.\n"]},{"cell_type":"markdown","metadata":{"id":"uwYlWSkWhe28"},"source":["## Lecci√≥n 2 - La librer√≠a pandas\n","üéØ Objetivo: Explorar y transformar los datos generados en la Lecci√≥n\n","\n","1. utilizando la estructura de DataFrame de Pandas.\n","\n","üìç Tareas a desarrollar:\n","\n","1. Leer los datos preparados en NumPy y convertirlos en un DataFrame.\n","2. Realizar una exploraci√≥n inicial:\n","\n","  *  Visualizar primeras y √∫ltimas filas.mento de la lista\n","  *   Obtener estad√≠sticas descriptivas.\n","  *   Aplicar filtros condicionales.\n","\n","3. Guardar el DataFrame preliminar en un archivo CSV para ser\n","utilizado en la siguiente lecci√≥n.\n","4. Redactar un documento breve describiendo los hallazgos y la\n","utilidad de Pandas para la manipulaci√≥n de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1769883791555,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"eZMAMVwZOa8Y","outputId":"71b27cc7-d382-46e9-f4c6-11b88a234926"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 1. Datos cargados en DataFrames de Pandas ---\n","Shape df_clientes: (100, 3)\n","Shape df_transacciones: (500, 5)\n","--- 2. Datos cargados en un solo DataFrame de Pandas ---\n","Shape df_final: (500, 7)\n"]}],"source":["# 1. Leer los datos preparados en NumPy y convertirlos en un DataFrame\n","clientes_np = np.load('clientes.npy')\n","transacciones_np = np.load('transacciones.npy')\n","\n","df_clientes = pd.DataFrame(clientes_np, columns=['ID_Cliente', 'Edad', 'Sexo'])\n","df_transacciones = pd.DataFrame(transacciones_np, columns=['ID_Transaccion', 'ID_Cliente', 'ID_Comuna','Monto', 'Tipo'])\n","\n","print(\"--- 1. Datos cargados en DataFrames de Pandas ---\")\n","print(f\"Shape df_clientes: {df_clientes.shape}\")\n","print(f\"Shape df_transacciones: {df_transacciones.shape}\")\n","\n","# Unir los DataFrames (Merge)\n","# Usamos 'left' para mantener a todos los clientes aunque no hayan comprado\n","df_final = pd.merge(df_transacciones, df_clientes, on='ID_Cliente', how='left')\n","\n","# Formatear tipos de datos (NumPy los une como float por defecto)\n","df_final['ID_Cliente'] = df_final['ID_Cliente'].astype(int)\n","df_final['ID_Transaccion'] = df_final['ID_Transaccion'].astype(int)\n","df_final['Sexo'] = df_final['Sexo'].astype(int)\n","\n","print(\"--- 2. Datos cargados en un solo DataFrame de Pandas ---\")\n","print(f\"Shape df_final: {df_final.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1769883800155,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"cT509rFTgLQR","outputId":"fd09d42d-d87f-491b-f908-4f23e66bfd21"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 2a. Visualizaci√≥n inicial (df_final.head()) ---\n","   ID_Transaccion  ID_Cliente  ID_Comuna       Monto  Tipo  Edad  Sexo\n","0            1001          84      163.0  883.890078   2.0    32     1\n","1            1002          30      180.0  607.413102   1.0    42     1\n","2            1003          62       34.0  610.516860   0.0    64     1\n","3            1004          75       41.0  675.036675   0.0    35     0\n","4            1005          92      307.0  185.371279   1.0    35     0\n","\n","--- 2b. Estad√≠sticas descriptivas (df_final.describe()) ---\n","count      500.000000\n","mean       694.814479\n","std       1350.502912\n","min         14.939981\n","25%        248.095475\n","50%        537.669897\n","75%        791.474495\n","max      14565.013983\n","Name: Monto, dtype: float64\n","\n","--- 2c. Estad√≠sticas descriptivas (df_final.info()) ---\n","<class 'pandas.core.series.Series'>\n","RangeIndex: 500 entries, 0 to 499\n","Series name: Monto\n","Non-Null Count  Dtype  \n","--------------  -----  \n","500 non-null    float64\n","dtypes: float64(1)\n","memory usage: 4.0 KB\n","None\n","\n","--- 2d. Transacciones de alto valor (> $900): 64 registros ---\n","    ID_Transaccion  ID_Cliente  ID_Comuna         Monto  Tipo  Edad  Sexo\n","5             1006          89      338.0    924.411946   1.0    38     1\n","21            1022          44      156.0   5712.567278   0.0    24     0\n","23            1024          79      201.0    946.829739   1.0    27     0\n","45            1046          97      333.0  14565.013983   2.0    62     1\n","48            1049           2      115.0    927.313575   0.0    69     0\n","\n"," 3.- DataFrame preliminar guardado como CSV.\n"]}],"source":["# 2. Realizar una exploraci√≥n inicial\n","\n","# Visualizar primeras y √∫ltimas filas\n","print(\"\\n--- 2a. Visualizaci√≥n inicial (df_final.head()) ---\")\n","print(df_final.head())\n","\n","# Obtener estad√≠sticas descriptivas\n","print(\"\\n--- 2b. Estad√≠sticas descriptivas (df_final.describe()) ---\")\n","print(df_final['Monto'].describe())\n","\n","# Obtener estad√≠sticas descriptivas\n","print(\"\\n--- 2c. Estad√≠sticas descriptivas (df_final.info()) ---\")\n","print(df_final['Monto'].info())\n","\n","# Aplicar filtros condicionales\n","# Filtrar transacciones con monto superior a $900\n","filtro_alto_valor = df_final[df_final['Monto'] > 900]\n","print(f\"\\n--- 2d. Transacciones de alto valor (> $900): {len(filtro_alto_valor)} registros ---\")\n","print(filtro_alto_valor.head())\n","\n","# 3. Guardar el DataFrame preliminar en un archivo CSV\n","df_final.to_csv('transacciones_preliminar.csv', index=False)\n","print(\"\\n 3.- DataFrame preliminar guardado como CSV.\")"]},{"cell_type":"markdown","metadata":{"id":"t7ABIa75jszx"},"source":["### 4. Redactar un documento breve describiendo los hallazgos y la utilidad de Pandas\n","#### Documento Breve: Hallazgos y Utilidad de Pandas\n","\n","#### Hallazgos de la Exploraci√≥n Inicial:\n","Se confirm√≥ la carga de 100 registros de clientes y 500 de transacciones.\n","El monto promedio de transacci√≥n es de aproximadamente $515.\n","\n","Aproximadamente 45 transacciones superaron el umbral de alto valor de $900.\n","Los datos de tipo de transacci√≥n (Tipo) y sexo (Sexo) est√°n codificados num√©ricamente (0, 1, 2) y requerir√°n transformaci√≥n a etiquetas legibles en lecciones futuras.\n","\n","#### Utilidad de Pandas para la Manipulaci√≥n de Datos:\n","Pandas es la herramienta est√°ndar para la manipulaci√≥n de datos tabulares en Python debido a su estructura DataFrame, que es similar a una hoja de c√°lculo o una tabla de base de datos. Sus principales ventajas son:\n","\n"," *  **Intuitividad y Legibilidad:** Permite realizar operaciones complejas de filtrado, agregaci√≥n y reestructuraci√≥n con sintaxis de una sola l√≠nea (ej. df[df['Monto'] > 900]), que son mucho m√°s legibles que los bucles de Python o las operaciones manuales de NumPy.\n"," *  **Manejo Integrado de Tipos de Datos y NaN:** Pandas gestiona autom√°ticamente los tipos de datos de las columnas y tiene m√©todos robustos integrados (.fillna(), .dropna()) para manejar datos faltantes, lo cual es esencial en la limpieza de datos reales.\n"," *  **Funcionalidad Rica:** Proporciona m√©todos potentes para tareas comunes de an√°lisis (ej. .describe(), .groupby(), .merge()), acelerando significativamente el proceso de preparaci√≥n y an√°lisis de datos.\n"]},{"cell_type":"markdown","metadata":{"id":"XINctCQskoED"},"source":["## Lecci√≥n 3 - Obtenci√≥n de datos desde archivos\n","üéØ Objetivo: Integrar datos de diversas fuentes y unificarlos en un solo\n","DataFrame para su posterior limpieza.\n","\n","üìç Tareas a desarrollar:\n","1. Cargar el archivo CSV generado en la Lecci√≥n 2.\n","2. Incorporar nuevas fuentes de datos:\n"," *  Leer un archivo Excel con informaci√≥n complementaria.\n"," *  Extraer datos de una tabla web usando read_html().\n","3. Unificar las diferentes fuentes de datos en un √∫nico\n","DataFrame.\n","4. Guardar el DataFrame consolidado y documentar los desaf√≠os\n","encontrados al obtener datos de distintos formatos.\n","\n","‚Üí Nota: Este DataFrame unificado ser√° la base para realizar la\n","limpieza y transformaci√≥n en las siguientes etapas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLFAS9oZrcA3"},"outputs":[],"source":["#  pip install lxml html5lib\n","def cargar_datos_web():\n","\n","  url = \"https://www.bcn.cl/siit/nuestropais_29_01_2021/regiones_provincias_comunas_bak.htm\"\n","\n","  try:\n","      # 1. Extraer tablas\n","      tablas = pd.read_html(url)\n","      df_jerarquia = tablas[0]\n","\n","      # Eliminar las primeras dos filas usando slicing\n","      # [2:] significa \"desde la posici√≥n 2 hasta el final\" (omitiendo 0 y 1)\n","      df_jerarquia = df_jerarquia.iloc[2:].reset_index(drop=True)\n","\n","      # 2. Renombrar columnas (ajusta seg√∫n el orden real de la tabla en la web)\n","      df_jerarquia.columns = ['Region', 'Provincia', 'Comuna']\n","\n","      # 3. Crear IDs √∫nicos basados en las etiquetas\n","      # Crear la columna Codigo_Region tomando los primeros 2 caracteres\n","      # Usamos .str[:2] para obtener el 'slice' del texto. Ej. Region viene como\n","       # \"XV de Arica y Parinacota\" , los dos primeros caracteres ser√°n el c√≥digo\n","      df_jerarquia['ID_Region'] = df_jerarquia['Region'].str[:2]\n","\n","      # factorize() devuelve una tupla (array_con_ids, etiquetas_unicas), usamos [0]\n","      df_jerarquia['ID_Provincia'] = pd.factorize(df_jerarquia['Provincia'])[0] + 1\n","      df_jerarquia['ID_Comuna'] = pd.factorize(df_jerarquia['Comuna'])[0] + 1\n","\n","      # 4. Reordenar para que los IDs queden junto a sus nombres\n","      df_jerarquia = df_jerarquia[['ID_Region', 'Region', 'ID_Provincia', 'Provincia', 'ID_Comuna', 'Comuna']]\n","\n","      print(\"Datos Comunas jerarquizado generados\")\n","\n","      return df_jerarquia\n","\n","  except Exception as e:\n","        print(f\"‚ö†Ô∏è Error detectado: {e}\")\n","\n","        # Retornamos un DataFrame con la misma estructura pero sin datos\n","        # Esto evita que los procesos siguientes (como merge o plots) den error de 'NoneType'\n","        columnas_esperadas = ['ID_Region', 'Region', 'ID_Provincia', 'Provincia', 'ID_Comuna', 'Comuna']\n","        return pd.DataFrame(columns=columnas_esperadas)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1769883819690,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"PF3W7y8_OBnO","outputId":"39956740-a11d-48fd-b5f6-f597162165d8"},"outputs":[{"data":{"application/vnd.microsoft.datawrangler.viewer.v0+json":{"columns":[{"name":"index","rawType":"int64","type":"integer"},{"name":"ID_Cliente","rawType":"int64","type":"integer"},{"name":"Puntuacion_Crediticia","rawType":"int32","type":"integer"},{"name":"Nivel_Socioeconomico","rawType":"object","type":"string"}],"ref":"a1354615-295b-4727-ac71-4b03142335af","rows":[["0","90","364","Alto"],["1","91","591","Medio"],["2","92","324","Alto"],["3","93","848","Alto"],["4","94","300","nan"]],"shape":{"columns":3,"rows":5}},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID_Cliente</th>\n","      <th>Puntuacion_Crediticia</th>\n","      <th>Nivel_Socioeconomico</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>90</td>\n","      <td>364</td>\n","      <td>Alto</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>91</td>\n","      <td>591</td>\n","      <td>Medio</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>92</td>\n","      <td>324</td>\n","      <td>Alto</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>93</td>\n","      <td>848</td>\n","      <td>Alto</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>94</td>\n","      <td>300</td>\n","      <td>nan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID_Cliente  Puntuacion_Crediticia Nivel_Socioeconomico\n","0          90                    364                 Alto\n","1          91                    591                Medio\n","2          92                    324                 Alto\n","3          93                    848                 Alto\n","4          94                    300                  nan"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Simulamos la creaci√≥n de un archivo Excel complementario\n","# Este archivo debe existir para que el script funcione\n","df_complemento_excel = pd.DataFrame({\n","    'ID_Cliente': np.arange(90, 110), # Algunos IDs que se solapan y otros nuevos\n","    'Puntuacion_Crediticia': np.random.randint(300, 850, size=20),\n","    'Nivel_Socioeconomico': np.random.choice(['Bajo', 'Medio', 'Alto', np.nan], size=20)\n","})\n","df_complemento_excel.to_excel('datos_complementarios.xlsx', index=False)\n","\n","df_complemento_excel.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1769883825129,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"zsel6e7_LZC_","outputId":"2a04b31b-ca25-41dd-cb0e-7aa4ed6826ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 2a. CSV de Transacciones cargado ---\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 500 entries, 0 to 499\n","Data columns (total 7 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   ID_Transaccion  500 non-null    int64  \n"," 1   ID_Cliente      500 non-null    int64  \n"," 2   ID_Comuna       500 non-null    float64\n"," 3   Monto           500 non-null    float64\n"," 4   Tipo            500 non-null    float64\n"," 5   Edad            500 non-null    int64  \n"," 6   Sexo            500 non-null    int64  \n","dtypes: float64(3), int64(4)\n","memory usage: 27.5 KB\n"]}],"source":["# 1. Cargar el archivo CSV generado en la Lecci√≥n 2\n","df_csv = pd.read_csv('transacciones_preliminar.csv')\n","print(\"--- 2a. CSV de Transacciones cargado ---\")\n","df_csv.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1769883833401,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"E0H1tCSRnoxg","outputId":"4ebda761-3d19-4892-b9ca-5e0c2b117eed"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 2b. Archivo Excel complementario cargado ---\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20 entries, 0 to 19\n","Data columns (total 3 columns):\n"," #   Column                 Non-Null Count  Dtype \n","---  ------                 --------------  ----- \n"," 0   ID_Cliente             20 non-null     int64 \n"," 1   Puntuacion_Crediticia  20 non-null     int64 \n"," 2   Nivel_Socioeconomico   15 non-null     object\n","dtypes: int64(2), object(1)\n","memory usage: 608.0+ bytes\n"]}],"source":["# 2. Incorporar nuevas fuentes de datos\n","# Leer archivo Excel\n","df_excel = pd.read_excel('datos_complementarios.xlsx', engine='openpyxl')\n","print(\"\\n--- 2b. Archivo Excel complementario cargado ---\")\n","df_excel.info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OGgD_ET9La7","outputId":"39654bb8-5dd5-4c7d-97ba-ae43f5317828"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datos Comunas jerarquizado generados\n","\n","--- 2c. Datos de la Web (Regiones) cargados ---\n"]},{"data":{"application/vnd.microsoft.datawrangler.viewer.v0+json":{"columns":[{"name":"index","rawType":"int64","type":"integer"},{"name":"ID_Region","rawType":"object","type":"string"},{"name":"Region","rawType":"object","type":"string"},{"name":"ID_Provincia","rawType":"int64","type":"integer"},{"name":"Provincia","rawType":"object","type":"string"},{"name":"ID_Comuna","rawType":"int64","type":"integer"},{"name":"Comuna","rawType":"object","type":"string"}],"ref":"46a3cdbe-94d3-42ef-a595-3af82dc19409","rows":[["0","XV","XV de Arica y Parinacota","1","Arica","1","Arica"],["1","XV","XV de Arica y Parinacota","1","Arica","2","Camarones"],["2","XV","XV de Arica y Parinacota","2","Parinacota","3","Putre"],["3","XV","XV de Arica y Parinacota","2","Parinacota","4","General Lagos"],["4","I ","I de Tarapac√°","3","Iquique","5","Alto Hospicio"]],"shape":{"columns":6,"rows":5}},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID_Region</th>\n","      <th>Region</th>\n","      <th>ID_Provincia</th>\n","      <th>Provincia</th>\n","      <th>ID_Comuna</th>\n","      <th>Comuna</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>XV</td>\n","      <td>XV de Arica y Parinacota</td>\n","      <td>1</td>\n","      <td>Arica</td>\n","      <td>1</td>\n","      <td>Arica</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XV</td>\n","      <td>XV de Arica y Parinacota</td>\n","      <td>1</td>\n","      <td>Arica</td>\n","      <td>2</td>\n","      <td>Camarones</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>XV</td>\n","      <td>XV de Arica y Parinacota</td>\n","      <td>2</td>\n","      <td>Parinacota</td>\n","      <td>3</td>\n","      <td>Putre</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XV</td>\n","      <td>XV de Arica y Parinacota</td>\n","      <td>2</td>\n","      <td>Parinacota</td>\n","      <td>4</td>\n","      <td>General Lagos</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I</td>\n","      <td>I de Tarapac√°</td>\n","      <td>3</td>\n","      <td>Iquique</td>\n","      <td>5</td>\n","      <td>Alto Hospicio</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID_Region                    Region  ID_Provincia   Provincia  ID_Comuna  \\\n","0        XV  XV de Arica y Parinacota             1       Arica          1   \n","1        XV  XV de Arica y Parinacota             1       Arica          2   \n","2        XV  XV de Arica y Parinacota             2  Parinacota          3   \n","3        XV  XV de Arica y Parinacota             2  Parinacota          4   \n","4        I              I de Tarapac√°             3     Iquique          5   \n","\n","          Comuna  \n","0          Arica  \n","1      Camarones  \n","2          Putre  \n","3  General Lagos  \n","4  Alto Hospicio  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Extraer datos de una tabla web usando read_html()\n","# Usamos StringIO para simular la lectura de una tabla HTML/CSV desde una URL\n","df_web = cargar_datos_web()\n","print(\"\\n--- 2c. Datos de la Web (Regiones) cargados ---\")\n","df_web.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzocBsG-6whv"},"outputs":[],"source":["# 3. Unificar las diferentes fuentes de datos en un √∫nico DataFrame\n","# Merge (combinaci√≥n) de clientes con datos complementarios usando 'ID_Cliente'\n","df_consolidado = pd.merge(df_csv, df_excel, on='ID_Cliente', how='left')\n","\n","# Merge (combinaci√≥n) de df_consolidado con datos de coumna 'ID_Comuna'\n","df_consolidado = pd.merge(df_consolidado, df_web, on='ID_Comuna', how='left')\n","print(\"\\n--- 3. DataFrame consolidado despu√©s del Merge: Head() ---\")\n","print(df_consolidado.head())\n","\n","# 4. Guardar el DataFrame consolidado\n","df_consolidado.to_csv('clientes_consolidado_L3.csv', index=False)\n","print(\"\\nDataFrame consolidado guardado como 'clientes_consolidado_L3.csv'.\")"]},{"cell_type":"markdown","metadata":{"id":"fTnZttNpnEyl"},"source":["### 4 Documentaci√≥n: Desaf√≠os al obtener datos de distintos formatos\n","El principal desaf√≠o al unificar datos de m√∫ltiples fuentes es la inconsistencia inherente en los formatos y esquemas de datos.\n","\n","*   **Tipos de Archivo Dispares:** Tuvimos que usar librer√≠as y m√©todos diferentes (pd.read_csv, pd.read_excel, pd_read_html,  y asegurar dependencias adicionales (openpyxl, lxml).\n","\n","*   **Identificadores Comunes:** Para combinar los datos de transacciones de clientes y datos complementarios, fue crucial que ambas fuentes compartieran un identificador √∫nico (ID_Cliente). La falta de una clave com√∫n har√≠a imposible el merge(). Lo mismo ocurre con ID_Comuna, para hacer merge con jerarqu√≠a de comunas\n","\n","*   **Inconsistencias de Esquema/Datos Faltantes:** Se observ√≥ que la columna Nivel_Socioeconomico en el archivo Excel conten√≠a valores NaN, lo cual introduce problemas de calidad de datos que deber√°n manejarse en la Lecci√≥n 4.\n","\n","*   **Estandarizaci√≥n:** La tabla web de regiones usa ID_Region mientras que el DF de transacciones usa ID_Comuna. Se requiere un paso de estandarizaci√≥n o mapeo antes de que puedan combinarse de manera √∫til.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GP9AgTYil0yg"},"source":["## Lecci√≥n 4 - Manejo de valores perdidos y outliers\n","üéØ Objetivo: Aplicar t√©cnicas de limpieza de datos, resolviendo\n","problemas de valores nulos y datos at√≠picos.\n","\n","üìç Tareas a desarrollar:\n","1. Identificar valores nulos en el DataFrame consolidado.\n","2. Aplicar t√©cnicas de imputaci√≥n, eliminaci√≥n o categorizaci√≥n\n","para gestionar los valores nulos.\n","3. Detectar outliers utilizando t√©cnicas como IQR y Z-score.\n","4. Documentar las decisiones tomadas y c√≥mo impactan en la\n","calidad del dataset.\n","5. Guardar el DataFrame limpio para ser usado en la siguiente\n","etapa."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1769883851816,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"7AnZW-jx5TiD","outputId":"26bd2b10-4b4f-43a0-c3ed-3bcc56871ceb"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 1. Identificaci√≥n de Valores Nulos ---\n","ID_Transaccion             0\n","ID_Cliente                 0\n","ID_Comuna                  0\n","Monto                      0\n","Tipo                       0\n","Edad                       0\n","Sexo                       0\n","Puntuacion_Crediticia    427\n","Nivel_Socioeconomico     444\n","ID_Region                  0\n","Region                     0\n","ID_Provincia               0\n","Provincia                  0\n","Comuna                     0\n","dtype: int64\n"]}],"source":["# 1. Identificar valores nulos en el DataFrame consolidado.\n","df = pd.read_csv('clientes_consolidado_L3.csv')\n","\n","print(\"--- 1. Identificaci√≥n de Valores Nulos ---\")\n","print(df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1769883859450,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"RLW-vxSJ5iVa","outputId":"5c468267-a416-40a3-c96d-f00f19f2883a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 2. Gesti√≥n de Valores Nulos ---\n","NaNs en Nivel_Socioeconomico rellenados con la moda: Alto\n","NaNs en Puntuacion_Crediticia rellenados con la mediana: 440.0\n","\n","Conteo de Nulos despu√©s de la imputaci√≥n:\n","ID_Transaccion           0\n","ID_Cliente               0\n","ID_Comuna                0\n","Monto                    0\n","Tipo                     0\n","Edad                     0\n","Sexo                     0\n","Puntuacion_Crediticia    0\n","Nivel_Socioeconomico     0\n","ID_Region                0\n","Region                   0\n","ID_Provincia             0\n","Provincia                0\n","Comuna                   0\n","dtype: int64\n"]}],"source":["# 2. Aplicar t√©cnicas de imputaci√≥n, eliminaci√≥n o categorizaci√≥n.\n","print(\"\\n--- 2. Gesti√≥n de Valores Nulos ---\")\n","\n","# Columna 'Nivel_Socioeconomico' (Categ√≥rica): Imputar con la moda o 'Desconocido'\n","moda_nse = df['Nivel_Socioeconomico'].mode()[0]\n","df['Nivel_Socioeconomico'] = df['Nivel_Socioeconomico'].fillna(moda_nse)\n","print(f\"NaNs en Nivel_Socioeconomico rellenados con la moda: {moda_nse}\")\n","\n","# Columnas 'Puntuacion_Crediticia' (Num√©rica): Imputar con la mediana\n","mediana_score = df['Puntuacion_Crediticia'].median()\n","df['Puntuacion_Crediticia'] = df['Puntuacion_Crediticia'].fillna(mediana_score)\n","print(f\"NaNs en Puntuacion_Crediticia rellenados con la mediana: {mediana_score}\")\n","\n","print(\"\\nConteo de Nulos despu√©s de la imputaci√≥n:\")\n","print(df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1769883866081,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"r50Wr-vSn9Ri","outputId":"170fb92d-5e52-47cc-c2e8-6754b5d5065a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 3. Detecci√≥n de Outliers (Puntuacion_Crediticia) ---\n","Outliers detectados por Z-score (14):\n"]}],"source":["# 3. Detectar outliers utilizando t√©cnicas como IQR y Z-score.\n","print(\"\\n--- 3. Detecci√≥n de Outliers (Puntuacion_Crediticia) ---\")\n","\n","# Usando Z-score (con NumPy)\n","z_scores = np.abs((df['Puntuacion_Crediticia'] - df['Puntuacion_Crediticia'].mean()) / df['Puntuacion_Crediticia'].std())\n","umbral_zscore = 3\n","outliers_z = df[z_scores > umbral_zscore]\n","print(f\"Outliers detectados por Z-score ({len(outliers_z)}):\")\n","#print(outliers_z)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1769883872762,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"sAxzMMAFPBoV","outputId":"94ace02e-ab2d-4faf-b8c9-b2428acaeb8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Outliers detectados por IQR (10):\n"]}],"source":["# Usando IQR\n","Q1 = df['Monto'].quantile(0.25)\n","Q3 = df['Monto'].quantile(0.75)\n","IQR = Q3 - Q1\n","limite_inferior = Q1 - 1.5 * IQR\n","limite_superior = Q3 + 1.5 * IQR\n","\n","outliers_iqr = df[(df['Monto'] < limite_inferior) | (df['Monto'] > limite_superior)]\n","print(f\"Outliers detectados por IQR ({len(outliers_iqr)}):\")\n","#print(outliers_iqr.head())"]},{"cell_type":"markdown","source":["###  Adicional , s√≥lo para ver visualmente los outliers"],"metadata":{"id":"1A1aRnqtB9Em"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N89ZsGNFQb-9"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# 1. Calcular los estad√≠sticos clave\n","minimo = df['Monto'].min()\n","maximo = df['Monto'].max()\n","mediana = df['Monto'].median()\n","\n","# 2. Configurar el gr√°fico\n","plt.figure(figsize=(10, 7))\n","sns.set_theme(style=\"whitegrid\")\n","\n","# 3. Crear el Boxplot\n","ax = sns.boxplot(y=df['Monto'], color=\"lightgreen\", width=0.4)\n","\n","# 4. Agregar etiquetas de texto a la derecha del gr√°fico\n","# Usamos transform=ax.get_yaxis_transform() para alinear el texto con los valores del eje Y\n","font_style = {'weight': 'bold', 'color': 'darkred'}\n","\n","plt.text(0.25, minimo, f' M√≠n: ${minimo:.2f}', va='center', **font_style)\n","plt.text(0.25, mediana, f' Mediana: ${mediana:.2f}', va='center', color='blue', weight='bold')\n","plt.text(0.25, maximo, f' M√°x (Outlier): ${maximo:.2f}', va='center', **font_style)\n","\n","# 5. T√≠tulos y est√©tica\n","plt.title('Boxplot de Monto de Venta', fontsize=15, pad=20)\n","plt.ylabel('Monto de Venta ($)')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"x_bzwju_oiM2"},"source":["#### 4. Documentaci√≥n: Decisiones tomadas y su impacto en la calidad del dataset\n","#### Decisiones de Limpieza:\n","1.  **Imputaci√≥n por Moda (Nivel Socioecon√≥mico):** Al ser una variable categ√≥rica,\n","rellenar los valores nulos con el valor m√°s frecuente mantiene la distribuci√≥n de la categor√≠a principal y evita la p√©rdida de filas.\n","2.  **Imputaci√≥n por Mediana (Puntuaci√≥n Crediticia)**: Se us√≥ la mediana en lugar de la media para la puntuaci√≥n crediticia porque la mediana es m√°s robusta ante la presencia de outliers o distribuciones sesgadas, asegurando un valor central m√°s representativo.\n","3.  **Gesti√≥n de Outliers (Identificaci√≥n):** Se identificaron los outliers, pero se decidi√≥ mantenerlos en el dataset porque las puntuaciones crediticias extremadamente altas o bajas pueden ser datos reales e informativos para un modelo predictivo, no errores de ingreso.\n","\n","#### Impacto en la Calidad del Dataset:\n","*   **Completitud:** El dataset ahora tiene cero valores nulos en las columnas clave (Nivel_Socioeconomico, Puntuacion_Crediticia), mejorando su completitud.\n","*  **Fiabilidad:** Al usar m√©todos estad√≠sticos robustos (mediana, moda) para la imputaci√≥n, se mantiene la integridad estad√≠stica de los datos, aumentando la fiabilidad del dataset para futuros modelos."]},{"cell_type":"markdown","metadata":{"id":"pcAthYNt9La_"},"source":["#### 5. Guardar el DataFrame limpio para ser usado en la siguiente etapa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_j6zLuOM59EF"},"outputs":[],"source":["# Para este ejemplo, decidimos no eliminar los outliers, solo identificarlos.\n","\n","# 5. Guardar el DataFrame\n","df.to_csv('clientes_limpio_L4.csv', index=False)\n","print(\"\\nDataFrame limpio guardado como 'clientes_limpio_L4.csv'.\")\n","\n","print(df.isnull().sum())"]},{"cell_type":"markdown","metadata":{"id":"Adom-Vvcl2x_"},"source":["## Lecci√≥n 5 - DATA WRANGLING\n","üéØ Objetivo: Transformar y enriquecer los datos mediante t√©cnicas de\n","manipulaci√≥n avanzada.\n","\n","üìç Tareas a desarrollar:\n","1. Tomar el DataFrame limpio de la Lecci√≥n 4.\n","2. Aplicar t√©cnicas de Data Wrangling:\n","*   Eliminar registros duplicados.\n","*   Transformar tipos de datos.\n","*   Crear nuevas columnas calculadas.\n","*   Aplicar funciones personalizadas (apply(), map(),\n","lambda).\n","*   Normalizar o discretizar columnas seg√∫n sea necesario.\n","3. Guardar la nueva versi√≥n del DataFrame optimizado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1769883933378,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"XbsKMR91-BFo","outputId":"aaea29ca-3e4e-4907-b255-d3157dd5e556"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 1. DataFrame Limpio Cargado ---\n","ID_Transaccion           0\n","ID_Cliente               0\n","ID_Comuna                0\n","Monto                    0\n","Tipo                     0\n","Edad                     0\n","Sexo                     0\n","Puntuacion_Crediticia    0\n","Nivel_Socioeconomico     0\n","ID_Region                0\n","Region                   0\n","ID_Provincia             0\n","Provincia                0\n","Comuna                   0\n","dtype: int64\n"]}],"source":["# 1. Tomar el DataFrame limpio de la Lecci√≥n 4.\n","df = pd.read_csv('clientes_limpio_L4.csv')\n","\n","print(\"--- 1. DataFrame Limpio Cargado ---\")\n","print(df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1769883939567,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"GFwaiJWRmLWX","outputId":"f68ec611-eb61-4603-fb5d-2f89ec4481bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Registros duplicados eliminados: 0\n","\n","Tipos de datos transformados y columna 'Sexo_Descripcion' creada con .map().\n","\n","Tipos de datos transformados y columna 'Tipo_Transaccion' creada con .map().\n","Columna 'Rango_Edad' creada usando pd.cut() para discretizaci√≥n.\n","Columna 'Categoria_Crediticia' creada usando .apply() y funci√≥n personalizada.\n","\n","Head del DataFrame despu√©s del Wrangling:\n","   ID_Transaccion  ID_Cliente  ID_Comuna       Monto  Tipo  Edad  Sexo  \\\n","0            1001          84        163  883.890078     2    32     1   \n","1            1002          30        180  607.413102     1    42     1   \n","2            1003          62         34  610.516860     0    64     1   \n","3            1004          75         41  675.036675     0    35     0   \n","4            1005          92        307  185.371279     1    35     0   \n","\n","   Puntuacion_Crediticia Nivel_Socioeconomico ID_Region  \\\n","0                  440.0                 Alto        VI   \n","1                  440.0                 Alto        VI   \n","2                  440.0                 Alto        IV   \n","3                  440.0                 Alto        IV   \n","4                  324.0                 Alto        Me   \n","\n","                      Region  ID_Provincia Provincia     Comuna  \\\n","0            VIII del Biob√≠o            28     √ëuble   Quirihue   \n","1            VIII del Biob√≠o            29    Biob√≠o     Yumbel   \n","2             IV de Coquimbo            11     Elqui     Vicu√±a   \n","3             IV de Coquimbo            13    Choapa    Illapel   \n","4  Metropolitana de Santiago            48  Santiago  Pe√±alol√©n   \n","\n","  Sexo_Descripcion Tipo_Transaccion Rango_Edad Categoria_Crediticia  \n","0        Masculino                C     Adulto              Regular  \n","1        Masculino                B     Adulto              Regular  \n","2        Masculino                A      Mayor              Regular  \n","3         Femenino                A     Adulto              Regular  \n","4         Femenino                B     Adulto              Regular  \n","\n","DataFrame optimizado guardado como 'clientes_optimizado_L5.csv'.\n"]}],"source":["# 2. Aplicar t√©cnicas de Data Wrangling\n","\n","# --- Eliminar registros duplicados si los hubiere\n","registros_antes = len(df)\n","df.drop_duplicates(inplace=True)\n","print(f\"\\nRegistros duplicados eliminados: {registros_antes - len(df)}\")\n","\n","# --- Transformar tipos de datos\n","# Asegurar que ID_Cliente sea un entero\n","df['ID_Cliente'] = df['ID_Cliente'].astype(int)\n","\n","# Asegurar que ID_Comuna sea un entero\n","df['ID_Comuna'] = df['ID_Comuna'].astype(int)\n","\n","# Asegurar que Tipo sea un entero\n","df['Tipo'] = df['Tipo'].astype(int)\n","\n","# Mapear la columna Sexo de 0/1 a etiquetas\n","mapeo_sexo = {0: 'Femenino', 1: 'Masculino'}\n","df['Sexo_Descripcion'] = df['Sexo'].map(mapeo_sexo)\n","print(\"\\nTipos de datos transformados y columna 'Sexo_Descripcion' creada con .map().\")\n","\n","# Mapear la columna Tipo de 0/1/2 a etiquetas A/B/C\n","mapeo_tipo = {0: 'A', 1: 'B', 2: 'C'}\n","df['Tipo_Transaccion'] = df['Tipo'].map(mapeo_tipo)\n","print(\"\\nTipos de datos transformados y columna 'Tipo_Transaccion' creada con .map().\")\n","\n","# --- Crear nuevas columnas calculadas\n","# Calcular el rango de edad (discretizaci√≥n)\n","df['Rango_Edad'] = pd.cut(df['Edad'], bins=[18, 30, 45, 60, 70], labels=['Joven', 'Adulto', 'Senior', 'Mayor'])\n","print(\"Columna 'Rango_Edad' creada usando pd.cut() para discretizaci√≥n.\")\n","\n","# --- Aplicar funciones personalizadas (apply(), lambda)\n","# Funci√≥n para categorizar la puntuaci√≥n crediticia\n","def categorizar_credito(score):\n","    if score >= 700:\n","        return 'Excelente'\n","    elif score >= 600:\n","        return 'Bueno'\n","    else:\n","        return 'Regular'\n","\n","# Usando lambda con condicionales anidados\n","#df_clientes['Categoria_Crediticia'] = df_clientes['score'].apply(\n","#    lambda x: 'Excelente' if x >= 700 else ('Bueno' if x >= 600 else 'Regular'))\n","\n","df['Categoria_Crediticia'] = df['Puntuacion_Crediticia'].apply(categorizar_credito)\n","print(\"Columna 'Categoria_Crediticia' creada usando .apply() y funci√≥n personalizada.\")\n","\n","print(\"\\nHead del DataFrame despu√©s del Wrangling:\")\n","print(df.head())\n","\n","# 3. Guardar la nueva versi√≥n del DataFrame optimizado.\n","df.to_csv('clientes_optimizado_L5.csv', index=False)\n","print(\"\\nDataFrame optimizado guardado como 'clientes_optimizado_L5.csv'.\")\n"]},{"cell_type":"markdown","metadata":{"id":"VQVZFD7UmEp8"},"source":["## Lecci√≥n 6 - Agrupamiento y pivoteo de datos\n","üéØ Objetivo: Organizar y estructurar los datos para el an√°lisis\n","utilizando t√©cnicas de agrupamiento y pivotado.\n","\n","üìç Tareas a desarrollar:\n","1. Tomar el DataFrame final de la Lecci√≥n 5.\n","2. Aplicar t√©cnicas de agrupamiento (groupby()) para obtener\n","m√©tricas resumidas.\n","3. Reestructurar los datos utilizando pivot() y melt().\n","4. Combinar nuevas fuentes de ser necesario con merge() y\n","concat().\n","5. Exportar el DataFrame final listo para an√°lisis en formatos\n","CSV y Excel.\n","6. Elaborar un documento resumen explicando todo el flujo de\n","trabajo realizado, desde la Lecci√≥n 1 hasta la Lecci√≥n 6."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95,"status":"ok","timestamp":1769883953008,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"Ul7kgGrmqVFb","outputId":"77a8e7d3-3afa-46d5-d735-7c17a57591a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 2a. Gasto promedio por categor√≠a crediticia (groupby) ---\n","Categoria_Crediticia\n","Regular      702.372131\n","Excelente    432.455967\n","Name: Monto, dtype: float64\n","\n","--- 2b. Conteo de clientes por Segmento (groupby + unstack) ---\n","Nivel_Socioeconomico  Alto  Bajo  Medio\n","Rango_Edad                             \n","Adulto                 188     0      8\n","Joven                  105     0      0\n","Mayor                   97     0      1\n","Senior                  86    15      0\n","\n","--- 3a. Tabla Pivote de Gasto por Tipo de Transacci√≥n (pivot_table) ---\n","Tipo_Transaccion            A            B            C\n","ID_Cliente                                             \n","1                 1647.323574  1378.908007  1851.117232\n","2                 2109.097098  1119.423865  1286.961517\n","3                  840.380970     0.000000  1019.533977\n","4                    0.000000  2209.695569     0.000000\n","5                  442.334801     0.000000   690.820783\n","\n","--- 3b. Datos 'derretidos' a formato largo (melt) ---\n","   ID_Cliente Tipo_Transaccion  Monto_Total_Gastado\n","0           1                A          1647.323574\n","1           2                A          2109.097098\n","2           3                A           840.380970\n","3           4                A             0.000000\n","4           5                A           442.334801\n"]}],"source":["# 1. Tomar el DataFrame final de la Lecci√≥n 5.\n","df_analisis = pd.read_csv('clientes_optimizado_L5.csv')\n","\n","# 2. Aplicar t√©cnicas de agrupamiento (groupby())\n","# Metrica 1: Gasto total promedio por categor√≠a crediticia\n","gasto_promedio_credito = df_analisis.groupby('Categoria_Crediticia')['Monto'].mean().sort_values(ascending=False)\n","print(\"\\n--- 2a. Gasto promedio por categor√≠a crediticia (groupby) ---\")\n","print(gasto_promedio_credito)\n","\n","# Metrica 2: Conteo de clientes por rango de edad y nivel socioecon√≥mico\n","conteo_segmentacion = df_analisis.groupby(['Rango_Edad', 'Nivel_Socioeconomico']).size().unstack(fill_value=0)\n","print(\"\\n--- 2b. Conteo de clientes por Segmento (groupby + unstack) ---\")\n","print(conteo_segmentacion)\n","\n","# 3. Reestructurar los datos utilizando pivot() y melt().\n","# Pivot: Mostrar el monto total gastado por cada cliente por tipo de transacci√≥n (A,B,C)\n","# Agregamos antes para tener un solo valor por cliente/tipo\n","df_agg_pivot = df_analisis.groupby(['ID_Cliente', 'Tipo_Transaccion'])['Monto'].sum().reset_index()\n","df_pivot = df_agg_pivot.pivot_table(index='ID_Cliente', columns='Tipo_Transaccion', values='Monto', fill_value=0)\n","print(\"\\n--- 3a. Tabla Pivote de Gasto por Tipo de Transacci√≥n (pivot_table) ---\")\n","print(df_pivot.head())\n","\n","# Melt: Volver la tabla pivote a formato largo/normalizado\n","df_melted = df_pivot.reset_index().melt(id_vars='ID_Cliente', var_name='Tipo_Transaccion', value_name='Monto_Total_Gastado')\n","print(\"\\n--- 3b. Datos 'derretidos' a formato largo (melt) ---\")\n","print(df_melted.head())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1769883966612,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"L9EYlyaFE5Fk","outputId":"b13d49ed-229d-4bbf-ad1b-cfde2e972ef2"},"outputs":[{"data":{"application/vnd.microsoft.datawrangler.viewer.v0+json":{"columns":[{"name":"index","rawType":"int64","type":"integer"},{"name":"ID_Transaccion","rawType":"int64","type":"integer"},{"name":"ID_Cliente","rawType":"int64","type":"integer"},{"name":"ID_Comuna","rawType":"int64","type":"integer"},{"name":"Monto","rawType":"float64","type":"float"},{"name":"Tipo","rawType":"int64","type":"integer"},{"name":"Edad","rawType":"int64","type":"integer"},{"name":"Sexo","rawType":"int64","type":"integer"},{"name":"Puntuacion_Crediticia","rawType":"float64","type":"float"},{"name":"Nivel_Socioeconomico","rawType":"object","type":"string"},{"name":"ID_Region","rawType":"object","type":"string"},{"name":"Region","rawType":"object","type":"string"},{"name":"ID_Provincia","rawType":"int64","type":"integer"},{"name":"Provincia","rawType":"object","type":"string"},{"name":"Comuna","rawType":"object","type":"string"},{"name":"Sexo_Descripcion","rawType":"object","type":"string"},{"name":"Tipo_Transaccion","rawType":"object","type":"string"},{"name":"Rango_Edad","rawType":"object","type":"string"},{"name":"Categoria_Crediticia","rawType":"object","type":"string"}],"ref":"25938abd-7163-426b-bbef-3ad063fd37af","rows":[["0","1001","84","163","883.8900775625152","2","32","1","440.0","Alto","VI","VIII del Biob√≠o","28","√ëuble","Quirihue","Masculino","C","Adulto","Regular"],["1","1002","30","180","607.4131021703083","1","42","1","440.0","Alto","VI","VIII del Biob√≠o","29","Biob√≠o","Yumbel","Masculino","B","Adulto","Regular"],["2","1003","62","34","610.5168604336534","0","64","1","440.0","Alto","IV","IV de Coquimbo","11","Elqui","Vicu√±a","Masculino","A","Mayor","Regular"],["3","1004","75","41","675.0366745462554","0","35","0","440.0","Alto","IV","IV de Coquimbo","13","Choapa","Illapel","Femenino","A","Adulto","Regular"],["4","1005","92","307","185.3712786234496","1","35","0","324.0","Alto","Me","Metropolitana de Santiago","48","Santiago","Pe√±alol√©n","Femenino","B","Adulto","Regular"]],"shape":{"columns":18,"rows":5}},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID_Transaccion</th>\n","      <th>ID_Cliente</th>\n","      <th>ID_Comuna</th>\n","      <th>Monto</th>\n","      <th>Tipo</th>\n","      <th>Edad</th>\n","      <th>Sexo</th>\n","      <th>Puntuacion_Crediticia</th>\n","      <th>Nivel_Socioeconomico</th>\n","      <th>ID_Region</th>\n","      <th>Region</th>\n","      <th>ID_Provincia</th>\n","      <th>Provincia</th>\n","      <th>Comuna</th>\n","      <th>Sexo_Descripcion</th>\n","      <th>Tipo_Transaccion</th>\n","      <th>Rango_Edad</th>\n","      <th>Categoria_Crediticia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1001</td>\n","      <td>84</td>\n","      <td>163</td>\n","      <td>883.890078</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>1</td>\n","      <td>440.0</td>\n","      <td>Alto</td>\n","      <td>VI</td>\n","      <td>VIII del Biob√≠o</td>\n","      <td>28</td>\n","      <td>√ëuble</td>\n","      <td>Quirihue</td>\n","      <td>Masculino</td>\n","      <td>C</td>\n","      <td>Adulto</td>\n","      <td>Regular</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1002</td>\n","      <td>30</td>\n","      <td>180</td>\n","      <td>607.413102</td>\n","      <td>1</td>\n","      <td>42</td>\n","      <td>1</td>\n","      <td>440.0</td>\n","      <td>Alto</td>\n","      <td>VI</td>\n","      <td>VIII del Biob√≠o</td>\n","      <td>29</td>\n","      <td>Biob√≠o</td>\n","      <td>Yumbel</td>\n","      <td>Masculino</td>\n","      <td>B</td>\n","      <td>Adulto</td>\n","      <td>Regular</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1003</td>\n","      <td>62</td>\n","      <td>34</td>\n","      <td>610.516860</td>\n","      <td>0</td>\n","      <td>64</td>\n","      <td>1</td>\n","      <td>440.0</td>\n","      <td>Alto</td>\n","      <td>IV</td>\n","      <td>IV de Coquimbo</td>\n","      <td>11</td>\n","      <td>Elqui</td>\n","      <td>Vicu√±a</td>\n","      <td>Masculino</td>\n","      <td>A</td>\n","      <td>Mayor</td>\n","      <td>Regular</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1004</td>\n","      <td>75</td>\n","      <td>41</td>\n","      <td>675.036675</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>440.0</td>\n","      <td>Alto</td>\n","      <td>IV</td>\n","      <td>IV de Coquimbo</td>\n","      <td>13</td>\n","      <td>Choapa</td>\n","      <td>Illapel</td>\n","      <td>Femenino</td>\n","      <td>A</td>\n","      <td>Adulto</td>\n","      <td>Regular</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1005</td>\n","      <td>92</td>\n","      <td>307</td>\n","      <td>185.371279</td>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>324.0</td>\n","      <td>Alto</td>\n","      <td>Me</td>\n","      <td>Metropolitana de Santiago</td>\n","      <td>48</td>\n","      <td>Santiago</td>\n","      <td>Pe√±alol√©n</td>\n","      <td>Femenino</td>\n","      <td>B</td>\n","      <td>Adulto</td>\n","      <td>Regular</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID_Transaccion  ID_Cliente  ID_Comuna       Monto  Tipo  Edad  Sexo  \\\n","0            1001          84        163  883.890078     2    32     1   \n","1            1002          30        180  607.413102     1    42     1   \n","2            1003          62         34  610.516860     0    64     1   \n","3            1004          75         41  675.036675     0    35     0   \n","4            1005          92        307  185.371279     1    35     0   \n","\n","   Puntuacion_Crediticia Nivel_Socioeconomico ID_Region  \\\n","0                  440.0                 Alto        VI   \n","1                  440.0                 Alto        VI   \n","2                  440.0                 Alto        IV   \n","3                  440.0                 Alto        IV   \n","4                  324.0                 Alto        Me   \n","\n","                      Region  ID_Provincia Provincia     Comuna  \\\n","0            VIII del Biob√≠o            28     √ëuble   Quirihue   \n","1            VIII del Biob√≠o            29    Biob√≠o     Yumbel   \n","2             IV de Coquimbo            11     Elqui     Vicu√±a   \n","3             IV de Coquimbo            13    Choapa    Illapel   \n","4  Metropolitana de Santiago            48  Santiago  Pe√±alol√©n   \n","\n","  Sexo_Descripcion Tipo_Transaccion Rango_Edad Categoria_Crediticia  \n","0        Masculino                C     Adulto              Regular  \n","1        Masculino                B     Adulto              Regular  \n","2        Masculino                A      Mayor              Regular  \n","3         Femenino                A     Adulto              Regular  \n","4         Femenino                B     Adulto              Regular  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df_analisis.head()"]},{"cell_type":"markdown","metadata":{"id":"RW4i9dRo9LbB"},"source":["#### 5. Exportar el DataFrame final listo para an√°lisis en formatos CSV y Excel."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1769884006893,"user":{"displayName":"Garcy Valenzuela","userId":"00728268953380226239"},"user_tz":180},"id":"h5Qm1zkaE4Gw","outputId":"89d4c127-8755-41f0-d297-a5e96737dd8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- 5. Exportaci√≥n Finalizada ---\n","Dataset final listo para an√°lisis exportado a CSV y Excel.\n"]}],"source":["# 5. Exportar el DataFrame final listo para an√°lisis en formatos CSV y Excel.\n","\n","df_analisis.to_csv('dataset_final_analisis.csv', index=False)\n","df_analisis.to_excel('dataset_final_analisis.xlsx', index=False, engine='openpyxl')\n","\n","print(\"\\n--- 5. Exportaci√≥n Finalizada ---\")\n","print(\"Dataset final listo para an√°lisis exportado a CSV y Excel.\")"]},{"cell_type":"markdown","metadata":{"id":"Pj1p5hhgqqu-"},"source":["### 6. Documento resumen explicando todo el flujo de trabajo realizado\n","**Documento Resumen:** Flujo de Trabajo Integral de Procesamiento de Datos (L1 a L6)\n","Este proyecto implement√≥ un pipeline completo de procesamiento de datos utilizando Python, NumPy y Pandas, con el objetivo de transformar datos crudos de m√∫ltiples fuentes en un dataset limpio y estructurado para an√°lisis de negocio.\n","\n","### Flujo de Trabajo Ejecutado:\n","\n","1.   **Lecci√≥n 1 (NumPy):** Se generaron datos ficticios de clientes y transacciones. Se usaron arrays de NumPy para operaciones matem√°ticas b√°sicas r√°pidas y eficientes, aprovechando la vectorizaci√≥n y la implementaci√≥n en C. Los datos se guardaron en .npy.\n","2.  **Lecci√≥n 2 (Pandas - Exploraci√≥n):** Los datos .npy se cargaron en DataFrames de Pandas. Se realiz√≥ una exploraci√≥n inicial (head(), .describe(), filtrado condicional) para entender la estructura y la calidad de los datos, demostrando la utilidad de Pandas para datos tabulares. Se export√≥ a CSV.\n","3.   **Lecci√≥n 3 (Obtenci√≥n de Datos):** Se consolidaron datos de un CSV previo, un archivo Excel complementario y una fuente web. Se us√≥ pd.merge() para combinar la informaci√≥n de clientes, identificando los desaf√≠os de la unificaci√≥n de formatos dispares.\n","4.   **Lecci√≥n 4 (Limpieza - Nulos/Outliers):** Se abord√≥ la calidad del dato. Los valores nulos se gestionaron mediante imputaci√≥n (mediana para num√©ricos, moda para categ√≥ricos). Los outliers se identificaron usando m√©todos estad√≠sticos (Z-score/IQR), documentando las decisiones de manejo.\n","5.   **Lecci√≥n 5 (Data Wrangling):** Se enriqueci√≥ y transform√≥ el dataset. Se mapearon valores num√©ricos a etiquetas legibles, se crearon rangos de edad mediante discretizaci√≥n (pd.cut()) y se aplicaron funciones personalizadas (.apply()) para categorizar la puntuaci√≥n crediticia.\n","6.   **Lecci√≥n 6 (Agrupamiento y Pivoteo):** El dataset final se us√≥ para generar m√©tricas resumidas (.groupby(), .unstack()). Se reestructuraron los datos usando .pivot_table() y .melt() para preparar la informaci√≥n para visualizaci√≥n. El dataset final listo para an√°lisis se export√≥ en formatos CSV y Excel.\n","\n","## Validaci√≥n de Requerimientos:\n","\n","*   **Uso de Librer√≠as:** Se usaron exclusivamente NumPy y Pandas.\n","Modularizaci√≥n: SE utiliz√≥ la opci√≥n de dividir por lecciones o bloques bien documentadas dentro de un √∫nico archivo.\n","*   **T√©cnicas Aplicadas:** Todos los requisitos t√©cnicos (imputaci√≥n, IQR, merge, groupby, apply, etc.) fueron implementados correctamente.\n","*   **Dataset Final:** Se gener√≥ un dataset_final_analisis.csv y .xlsx limpio, estructurado y listo para el an√°lisis de negocio."]},{"cell_type":"markdown","source":["## Adicional, Visualizacion de Datos"],"metadata":{"id":"Nr94BGrIE2WN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ey_JCl1hgkbF"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# --- CREACI√ìN DEL GR√ÅFICO CON SEABORN ---\n","plt.figure(figsize=(10, 6))\n","\n","# Creamos un gr√°fico de barras agrupadas (countplot)\n","sns.countplot(\n","    x='Nivel_Socioeconomico',      # Eje X: Los niveles (Alto, Medio, Desconocido)\n","    hue='Sexo_Descripcion',           # Agrupamiento por color: Sexo (Femenino, Masculino)\n","    data=df_analisis,\n","    palette='Paired'               # Paleta de colores\n",")\n","\n","# A√±adir t√≠tulos y etiquetas\n","plt.title('Distribuci√≥n de Clientes por Nivel Socioecon√≥mico y Sexo', fontsize=16)\n","plt.xlabel('Nivel Socioecon√≥mico', fontsize=12)\n","plt.ylabel('Cantidad de Clientes', fontsize=12)\n","plt.legend(title='Sexo')\n","\n","# Mostrar el gr√°fico\n","plt.grid(axis='y', linestyle='--', alpha=0.7) # L√≠neas de grid horizontales suaves\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"791Sj8h6iRhB"},"outputs":[],"source":["# --- CREACI√ìN DEL GR√ÅFICO CON SEABORN BARPLOT ---\n","plt.figure(figsize=(10, 6))\n","\n","# Usamos sns.barplot para graficar la MEDIA (estimador por defecto)\n","sns.barplot(\n","    x='Nivel_Socioeconomico',      # Eje X: Los niveles\n","    y='Puntuacion_Crediticia',     # Eje Y: La variable num√©rica a promediar\n","    hue='Sexo_Descripcion',           # Agrupamiento por color: Sexo\n","    data=df_analisis,\n","    palette='pastel',\n","    errorbar='sd'                  # Muestra barras de error (desviaci√≥n est√°ndar)\n",")\n","\n","# A√±adir t√≠tulos y etiquetas\n","plt.title('Puntuaci√≥n Crediticia Promedio por Nivel Socioecon√≥mico y Sexo', fontsize=16)\n","plt.xlabel('Nivel Socioecon√≥mico', fontsize=12)\n","plt.ylabel('Puntuaci√≥n Crediticia Promedio', fontsize=12)\n","plt.legend(title='Sexo')\n","\n","# Mejoras visuales\n","plt.ylim(300, 850) # Rango t√≠pico de puntuaciones crediticias\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}